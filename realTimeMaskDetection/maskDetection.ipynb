{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceMaskDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (224,224))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceMaskDetector:\n",
    "    def __init__(self, model_path):\n",
    "        self.device = torch.device('cpu')\n",
    "        self.model = self.load_model(model_path).to(self.device)\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    def load_model(self, model_path):\n",
    "        model = models.resnet50(pretrained=False)\n",
    "        num_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_features, 2)\n",
    "        model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
    "        model.eval()\n",
    "        return model\n",
    "    def detect(self, frame):\n",
    "        frame= self.transform(frame).unsqueeze(0).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            output = self.model(frame)\n",
    "        probabilities = torch.softmax(output, dim=1)[0]\n",
    "        mask_probability = probabilities[1].item()\n",
    "        no_mask_probability = probabilities[0].item()\n",
    "        label = 'Mask' if mask_probability > no_mask_probability else \"No Mask\"\n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = \"./Face Mask Dataset/Train/\"\n",
    "validation = \"./Face Mask Dataset/Validation/\"\n",
    "test = \"./Face Mask Dataset/Test/\"\n",
    "model_save_path = \"./\"\n",
    "batch_size = 16\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_paths = []\n",
    "train_labels = []\n",
    "\n",
    "for folder_name in os.listdir(train):\n",
    "    folder_path = os.path.join(train, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith(\".png\"):\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                train_images_paths.append(file_path)\n",
    "                train_labels.append(0 if folder_name =='WithMask' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_images_paths = []\n",
    "validation_labels = []\n",
    "\n",
    "for folder_name in os.listdir(validation):\n",
    "    folder_path = os.path.join(validation, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith(\".png\"):\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                train_images_paths.append(file_path)\n",
    "                train_labels.append(0 if folder_name =='WithMask' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_paths = []\n",
    "test_labels = []\n",
    "\n",
    "for folder_name in os.listdir(test):\n",
    "    folder_path = os.path.join(test, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith(\".png\"):\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                train_images_paths.append(file_path)\n",
    "                train_labels.append(0 if folder_name =='WithMask' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FaceMaskDataset(train_images_paths, train_labels, transform=transforms.ToTensor())\n",
    "val_dataset = FaceMaskDataset(validation_images_paths, validation_labels, transform=transforms.ToTensor())\n",
    "test_dataset =FaceMaskDataset(test_images_paths, test_labels, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceMaskModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FaceMaskModel, self).__init__()\n",
    "        self.model = models.resnet50(pretrained=True)\n",
    "        num_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(num_features, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FaceMaskModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += (predicted == labels).sum().item()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    train_accuracy = correct/total\n",
    "    train_loss = running_loss/len(train_loader)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            val_loss += loss.item()\n",
    "    val_accuracy = val_correct/val_total\n",
    "    val_loss = val_loss/len(validation_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch +1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train accuracy: {train_accuracy*100:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | val accuracy: {val_accuracy*100:.2f}%\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_correct =0\n",
    "test_total=0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        _,predicted = torch.max(outputs.data, 1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "        test_loss += loss.item()\n",
    "test_accuracy = test_correct/test_total\n",
    "test_loss = test_loss/len(test_loader)\n",
    "\n",
    "print(f\"Test loss:{test_loss:.4f} | Test accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "torch.save(model, 'faceMaskDetection.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('faceMaskDetection.h5')\n",
    "model.eval() \n",
    "\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "def detect_face_mask(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=4)\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_roi = gray[y:y+h, x:x+w]\n",
    "        face_roi = cv2.resize(face_roi, (224, 224))\n",
    "        face_roi = face_roi / 255.0\n",
    "        face_roi = np.expand_dims(face_roi, axis=0)\n",
    "        face_roi = np.expand_dims(face_roi, axis=-1)\n",
    "        face_tensor = torch.tensor(face_roi, dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            output = model(face_tensor)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "        label = \"Mask\" if predicted.item() == 1 else \"No Mask\"\n",
    "        color = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
    "        cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "    return frame\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = detect_face_mask(frame)\n",
    "    cv2.imshow('Face Mask Detection', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
